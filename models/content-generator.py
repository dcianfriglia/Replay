import os
import requests
import json
import logging
from typing import Dict, Any, Optional, List

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ContentGenerator:
    """
    A class to handle content generation using LLM APIs
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize the content generator
        
        Args:
            api_key: API key for the LLM provider (defaults to env variable)
        """
        # Try to get API key from environment if not provided
        self.api_key = api_key or os.environ.get("LLM_API_KEY")
        
        # Default settings
        self.default_model = "claude-3-5-sonnet"
        self.base_url = "https://api.anthropic.com/v1/messages"
        self.max_tokens = 4000
        self.temperature = 0.7
    
    def generate(self, 
                prompt: str, 
                model: Optional[str] = None,
                max_tokens: Optional[int] = None,
                temperature: Optional[float] = None,
                additional_params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Generate content using the LLM API
        
        Args:
            prompt: The prompt to send to the LLM
            model: The model to use (defaults to claude-3-5-sonnet)
            max_tokens: Maximum tokens in the response
            temperature: Temperature parameter for generation
            additional_params: Any additional parameters to pass to the API
            
        Returns:
            Dict containing the response and metadata
        """
        # Use default values if not specified
        model = model or self.default_model
        max_tokens = max_tokens or self.max_tokens
        temperature = temperature or self.temperature
        
        # Check if API key is available
        if not self.api_key:
            logger.warning("No API key available. Using simulated response.")
            return self._simulate_response(prompt)
        
        # Prepare API request
        headers = {
            "Content-Type": "application/json",
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01"
        }
        
        # Prepare request data
        data = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        # Add any additional parameters
        if additional_params:
            data.update(additional_params)
        
        try:
            # Make API request
            logger.info(f"Sending request to LLM API with {len(prompt)} chars")
            response = requests.post(
                self.base_url,
                headers=headers,
                json=data
            )
            
            # Check if request was successful
            response.raise_for_status()
            
            # Parse response
            result = response.json()
            logger.info("Successfully received LLM API response")
            
            return {
                "success": True,
                "content": result.get("content", [{"text": "No content returned"}])[0]["text"],
                "model": model,
                "usage": result.get("usage", {}),
                "metadata": {
                    "prompt_tokens": result.get("usage", {}).get("input_tokens", 0),
                    "completion_tokens": result.get("usage", {}).get("output_tokens", 0),
                    "total_tokens": result.get("usage", {}).get("total_tokens", 0),
                }
            }
        
        except requests.exceptions.RequestException as e:
            logger.error(f"API request failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "content": self._fallback_response(prompt),
                "model": model
            }
    
    def _simulate_response(self, prompt: str) -> Dict[str, Any]:
        """
        Simulate a response when API is not available
        
        Args:
            prompt: The prompt that would have been sent
            
        Returns:
            Dict containing simulated response
        """
        logger.info("Simulating LLM API response")
        
        # Generate a simple simulated response based on the prompt
        content = f"""## Simulated Response

This is a simulated response since no API key was provided. In a real implementation, 
this would be generated by the LLM based on your prompt.

### Summary of Your Prompt

Your prompt was about implementing Agile methodologies in software development teams.
Here's a simulated response based on that topic:

## Implementing Agile in Software Development

Agile methodologies have revolutionized software development by emphasizing iterative progress, 
team collaboration, and customer feedback. This guide will help you understand and implement 
Agile practices in your organization.

### Understanding Agile Foundations

At its core, Agile is built on four key values from the Agile Manifesto:
1. Individuals and interactions over processes and tools
2. Working software over comprehensive documentation
3. Customer collaboration over contract negotiation
4. Responding to change over following a plan

### Key Agile Methodologies

#### Scrum
- Sprint planning, daily standups, sprint reviews, and retrospectives
- Defined roles: Product Owner, Scrum Master, Development Team
- Artifacts: Product Backlog, Sprint Backlog, Increment

#### Kanban
- Visual board with columns representing stages of work
- Work items move across the board as they progress
- Focus on limiting WIP to identify bottlenecks

### Implementing Agile in Your Team

1. Start with a pilot project
2. Build your Agile team
3. Establish ceremonies
4. Create and manage your backlog
5. Measure and improve

This is just a simulated response. Connect to a real LLM API for high-quality content generation.
"""

        return {
            "success": True,
            "content": content,
            "model": "simulated-model",
            "metadata": {
                "prompt_tokens": len(prompt.split()),
                "completion_tokens": len(content.split()),
                "total_tokens": len(prompt.split()) + len(content.split()),
                "simulated": True
            }
        }
    
    def _fallback_response(self, prompt: str) -> str:
        """
        Generate a fallback response when API request fails
        
        Args:
            prompt: The prompt that failed
            
        Returns:
            A fallback response message
        """
        return """
## API Request Failed

There was an error connecting to the LLM API. This could be due to:

- Network connectivity issues
- Invalid API key
- API rate limits
- Service outage

Please check your configuration and try again. In the meantime, you can:

1. Verify your API key is correct
2. Check your internet connection
3. Try again in a few minutes
4. Review the error logs for more details

If the problem persists, you may want to use the simulated mode for testing.
"""
    
    def batch_generate(self, prompts: List[str], **kwargs) -> List[Dict[str, Any]]:
        """
        Generate content for multiple prompts
        
        Args:
            prompts: List of prompts to process
            **kwargs: Additional parameters to pass to generate()
            
        Returns:
            List of response dictionaries
        """
        return [self.generate(prompt, **kwargs) for prompt in prompts]


# Function for simpler API access
def generate_content(prompt: str, **kwargs) -> str:
    """
    Generate content using the default ContentGenerator
    
    Args:
        prompt: The prompt to send to the LLM
        **kwargs: Additional parameters to pass to generate()
        
    Returns:
        The generated content as a string
    """
    generator = ContentGenerator()
    result = generator.generate(prompt, **kwargs)
    return result["content"]


if __name__ == "__main__":
    # Example usage
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    generator = ContentGenerator(api_key=api_key)
    
    test_prompt = """
    Write a short explanation of how neural networks work.
    Keep it simple and beginner-friendly.
    """
    
    result = generator.generate(test_prompt)
    print(result["content"])